Behavior = gsub(pattern = " ", replacement = "", x = Behavior),
DeltaHours = Delta_Time_s/3600,
# Total_Vessels = rowSums(across(c(TR,M))),
# pull hour as time object along with date
Hr_time = paste(Begin_Date, Begin_Clock),
# get components of date-time object and assign time zone
Hr_time = parse_date_time(Hr_time, "y/m/d H:M:S", tz = {.y}$tz_files),
# change to local time zone
Hr_local = with_tz(Hr_time, tzone = {.y}$tz_local),
# pull out new hour and date in local time
Begin_Hour_loc = as.numeric(hour(Hr_local)),
Begin_Date_loc = date(Hr_local),
# add weekday column
Weekday = weekdays(Begin_Date_loc))) |>
bind_rows()
# write csv for easier input later
write.csv(selns_data, "data_outputs/total_ves_selns_data_by_site.csv")
# Bind rows to get df for inside-outside tables
# don't need to do other adjustments for time zone etc bc will join with selns_data which has
# Begin_hour_loc and Begin_date_loc fields
ins_out_data <- ins_out_og |>
map(~select(., Filename, Date, Selection, used, pins_sm, pins_med, pins_lg, pins_ovrll, Dep_ID)) |>
map(~mutate(., Date = as.numeric(Date),
Date = as.character(Date))) |>
bind_rows()
# write csv for easier input later
write.csv(ins_out_data, "data_outputs/total_ves_ins_out_by_site.csv")
ins_vessels <- ins_out_data |>
filter(used == 1) |>
filter(pins_sm >= 0.75) |>
mutate(begin_file_date = ymd(str_sub(Date, 1,6)),
seln_num = as.numeric(gsub(pattern = "S", replacement = "", x = Selection)))|>
left_join(selns_data,
by = c("Dep_ID" = "Dep",
"seln_num" = "Selection",
"begin_file_date" = "Begin_file_date"))
# get counts per site per date per hour for inside vessels
# will it break to just try....
ins_hp <- inside_tables_to_hp(ins_table = ins_vessels)
id_to_check <- which(is.na(ins_vessels$Begin_Date_loc))
x <- ins_vessels[id_to_check,]
write_csv(x, file = "data_outputs/inside_ves_to_check.csv")
write_csv(x, file = "data_outputs/inside_ves_to_check.csv")
View(ins_out_data)
View(ins_vessels)
View(selns_data)
ins_vessels <- ins_out_data |>
filter(used == 1) |>
filter(pins_sm >= 0.75) |>
mutate(begin_file_date = ymd(str_sub(Date, 1,6)),
seln_num = as.numeric(gsub(pattern = "S", replacement = "", x = Selection)))
View(ins_out_data)
View(ins_out_og)
ins_out_data <- ins_out_og |>
map(~select(., Filename, Date, Selection, used, pins_sm, pins_med, pins_lg, pins_ovrll, Dep_ID)) |>
map(~mutate(., Date = as.numeric(Date),
Date = as.character(Date))) |>
bind_rows()
View(ins_out_data)
ins_out_data <- ins_out_og |>
# map(~select(., Filename, Date, Selection, used, pins_sm, pins_med, pins_lg, pins_ovrll, Dep_ID)) |>
# map(~mutate(., Date = as.numeric(Date),
#             Date = as.character(Date))) |>
bind_rows()
View(ins_out_data)
View(ins_out_og)
unique(ins_out_og$CGMP_201904_CG$Dep_ID)
208+206+327+31+78+101+164+130+135+82+167
unique(ins_out_og$NINGALOO_201909_NGN$Dep_ID)
unique(ins_out_og$NINGALOO_201909_NGS$Dep_ID)
unique(ins_out_og$CGMP_201807_CG$Dep_ID)
unique(ins_out_og$CGMP_201812_CG$Dep_ID)
unique(ins_out_og$CGMP_201904_CG$Dep_ID)
View(ins_out_og$CGMP_201812_CG)
# For each deployment in the dep_info list, load in I-O excel files
ins_out_og <- dep_info |>
map(~read_xlsx(choose.files(caption = paste0({.}$site_id, {.}$dep_id, " I-O table .xlsx"))))|>
# use imap() to get info based on index of each iteration
# in this case, we want the name of the list element, designated as ".y"
imap(~mutate(., Dep_ID = .y))
ins_out_data <- ins_out_og |>
map(~select(., Filename, Date, Selection, used, pins_sm, pins_med, pins_lg, pins_ovrll, Dep_ID)) |>
map(~mutate(., Date = as.numeric(Date),
Date = as.character(Date))) |>
bind_rows()
# write csv for easier input later
write.csv(ins_out_data, "data_outputs/total_ves_ins_out_by_site.csv")
ins_vessels <- ins_out_data |>
filter(used == 1) |>
filter(pins_sm >= 0.75) |>
mutate(begin_file_date = ymd(str_sub(Date, 1,6)),
seln_num = as.numeric(gsub(pattern = "S", replacement = "", x = Selection)))|>
left_join(selns_data,
by = c("Dep_ID" = "Dep",
"seln_num" = "Selection",
"begin_file_date" = "Begin_file_date"))
# get counts per site per date per hour for inside vessels
# will it break to just try....
ins_hp <- inside_tables_to_hp(ins_table = ins_vessels)
id_to_check <- which(is.na(ins_vessels$Begin_Date_loc))
x <- ins_vessels[id_to_check,]
write_csv(x, file = "data_outputs/inside_ves_to_check.csv")
# For each deployment in the dep_info list, load in I-O excel files
ins_out_og <- dep_info |>
map(~read_xlsx(choose.files(caption = paste0({.}$site_id, {.}$dep_id, " I-O table .xlsx"))))|>
# use imap() to get info based on index of each iteration
# in this case, we want the name of the list element, designated as ".y"
imap(~mutate(., Dep_ID = .y))
ins_out_data <- ins_out_og |>
map(~select(., Filename, Date, Selection, used, pins_sm, pins_med, pins_lg, pins_ovrll, Dep_ID)) |>
map(~mutate(., Date = as.numeric(Date),
Date = as.character(Date))) |>
bind_rows()
# write csv for easier input later
write.csv(ins_out_data, "data_outputs/total_ves_ins_out_by_site.csv")
ins_vessels <- ins_out_data |>
filter(used == 1) |>
filter(pins_sm >= 0.75) |>
mutate(begin_file_date = ymd(str_sub(Date, 1,6)),
seln_num = as.numeric(gsub(pattern = "S", replacement = "", x = Selection)))|>
left_join(selns_data,
by = c("Dep_ID" = "Dep",
"seln_num" = "Selection",
"begin_file_date" = "Begin_file_date"))
# get counts per site per date per hour for inside vessels
# will it break to just try....
ins_hp <- inside_tables_to_hp(ins_table = ins_vessels)
# join inside vessels to total vessels
total_ins_hp <- hp_data |>
left_join(ins_hp,
by = c("Dep" = "Dep_ID",
"Begin_Date_loc" = "Begin_Date_loc",
"Begin_Hour_loc" = "Begin_Hour_loc"))
write.csv(total_ins_hp, "data_outputs/hourly_pres_allsites_local.csv")
View(ins_hp)
View(total_ins_hp)
View(selns_data)
# For each deployment in the dep_info list, load in compiled selection table
selns_og <- dep_info |>
map(~read_delim(choose.files(caption = paste0({.}$site_id, {.}$dep_id, " Complied seln table .txt"))))|>
# use imap() to get info based on index of each iteration
# in this case, we want the name of the list element, designated as ".y"
imap(~mutate(., Dep_ID = .y))
# reshape selection tables to plot duration
selns_data <- selns_og |>
map(~rename(., "Dep" = "Dep_ID")) |>
map2(.y = dep_info,
~mutate(.x,
Begin_Date = ymd(Begin_Date),
Begin_file_date = ymd(Begin_file_date),
Site_ID = {.y}$site_id,
# Dep = {.y}$dep_id,
# re-code anything with a maneuver as "Maneuver" (e.g., "Maneuver+CPA" = "Maneuver")
Behavior = gsub(pattern = ".*Maneuver.*", replacement = "Maneuver", x = Behavior),
# re-code all transit as "Transit" (e.g., "TransitA" = "Transit")
# important that this happens AFTER the Maneuver line above so that "TransitAManeuver" doesn't get re-coded
Behavior = gsub(pattern = ".*Transit.*", replacement = "Transit", x = Behavior),
Behavior = gsub(pattern = "CPAManeuver", replacement = "Maneuver", x = Behavior),
Behavior = gsub(pattern = "CPA", replacement = "Transit", x = Behavior),
Behavior = gsub(pattern = " ", replacement = "", x = Behavior),
DeltaHours = Delta_Time_s/3600,
# Total_Vessels = rowSums(across(c(TR,M))),
# pull hour as time object along with date
Hr_time = paste(Begin_Date, Begin_Clock),
# get components of date-time object and assign time zone
Hr_time = parse_date_time(Hr_time, "y/m/d H:M:S", tz = {.y}$tz_files),
# change to local time zone
Hr_local = with_tz(Hr_time, tzone = {.y}$tz_local),
# pull out new hour and date in local time
Begin_Hour_loc = as.numeric(hour(Hr_local)),
Begin_Date_loc = date(Hr_local),
# add weekday column
Weekday = weekdays(Begin_Date_loc))) |>
bind_rows()
# write csv for easier input later
write.csv(selns_data, "data_outputs/total_ves_selns_data_by_site.csv")
ins_vessels <- ins_out_data |>
filter(used == 1) |>
filter(pins_sm >= 0.75) |>
mutate(begin_file_date = ymd(str_sub(Date, 1,6)),
seln_num = as.numeric(gsub(pattern = "S", replacement = "", x = Selection)))|>
left_join(selns_data,
by = c("Dep_ID" = "Dep",
"seln_num" = "Selection",
"begin_file_date" = "Begin_file_date"))
# get counts per site per date per hour for inside vessels
ins_hp <- inside_tables_to_hp(ins_table = ins_vessels)
# join inside vessels to total vessels
total_ins_hp <- hp_data |>
left_join(ins_hp,
by = c("Dep" = "Dep_ID",
"Begin_Date_loc" = "Begin_Date_loc",
"Begin_Hour_loc" = "Begin_Hour_loc"))
site_id <- "SIMP_EP"
dep_id <- 201906
write.table(all_selns,
paste0("data_outputs/", site_id,"_",dep_id,"_all_vessel_selections.txt"),
row.names = FALSE)
#### Compile Vessel Selections from Raven ####
all_selns <- Compile_Raven_selns(site_id = site_id,
dep_id = dep_id)
write.table(all_selns,
paste0("data_outputs/", site_id,"_",dep_id,"_all_vessel_selections.txt"),
row.names = FALSE)
all_selns_hr <- all_selns |>
mutate(Begin_Clock = as_datetime(Begin_Clock, format = "%H:%M:%OS"),
End_Clock = as_datetime(End_Clock, format = "%H:%M:%OS"),
Begin_Date = as_datetime(Begin_Date, format = "%Y/%m/%d"),
Begin_Hour = hour(Begin_Clock),
End_Hour = hour(End_Clock),
# re-code anything with a maneuver as "Maneuver" (e.g., "Maneuver+CPA" = "Maneuver")
Behavior = gsub(pattern = ".*Maneuver.*", replacement = "Maneuver", x = Behavior),
# re-code all transit as "Transit" (e.g., "TransitA" = "Transit")
# important that this happens AFTER the Maneuver line above so that "TransitAManeuver" doesn't get re-coded
Behavior = gsub(pattern = ".*Transit.*", replacement = "Transit", x = Behavior),
Behavior = gsub(pattern = "CPAManeuver", replacement = "Maneuver", x = Behavior),
Behavior = gsub(pattern = "CPA", replacement = "Transit", x = Behavior),
Behavior = gsub(pattern = " ", replacement = "", x = Behavior),
Behavior = na_if(Behavior, ""),
Behavior = replace_na(Behavior, "Not_Assigned"))
# Count instances of each behavior per date-hour
hr_tally <- all_selns_hr |>
mutate(Behavior = as.factor(Behavior)) |>
group_by(Behavior, Begin_Date, Begin_Hour) |>
count() |>
# pivot wider to get behavs as columns and fill missing values with 0
pivot_wider(names_from = Behavior,
values_from = n,
values_fill = 0)
# create a new df with all hours for the whole deployment
date_range_dep <- seq.Date(from = start_dep_date, to = end_dep_date, by = "day") |>
crossing(seq(0,23,1))
# rename columns
names(date_range_dep) <- c("Begin_Date","Begin_Hour")
# join 2 data frames together to add behavior tally
hourly_pres <- date_range_dep |>
left_join(hr_tally, by = c("Begin_Date","Begin_Hour")) |>
replace_na(list(Transit = 0, Maneuver = 0))
# bring in Notes from all_selns_hr
seln_notes <- aggregate(Notes ~ Begin_Date + Begin_Hour, data = all_selns_hr, paste0, collapse = "; ") |>
# get rid of blank entries for notes
filter(Notes != "" & Notes != "; ")
hourly_pres_notes <- hourly_pres |>
left_join(seln_notes, by = c("Begin_Date","Begin_Hour")) |>
mutate(SiteID = site_id)
write.csv(hourly_pres_notes,
paste0("data_outputs/",site_id,"_",dep_id,"_Vessel_Hourly_Presence.csv"))
View(all_selns)
View(all_selns_hr)
#### Compile Vessel Selections from Raven ####
all_selns <- Compile_Raven_selns(site_id = site_id,
dep_id = dep_id)
write.table(all_selns,
paste0("data_outputs/", site_id,"_",dep_id,"_all_vessel_selections.txt"),
row.names = FALSE)
#### Create Hourly Presence Table ####
# get hours from date-times with functions from lubridate pkg
all_selns_hr <- all_selns |>
mutate(Begin_Clock = as_datetime(Begin_Clock, format = "%H:%M:%OS"),
End_Clock = as_datetime(End_Clock, format = "%H:%M:%OS"),
Begin_Date = as_datetime(Begin_Date, format = "%Y/%m/%d"),
Begin_Hour = hour(Begin_Clock),
End_Hour = hour(End_Clock),
# re-code anything with a maneuver as "Maneuver" (e.g., "Maneuver+CPA" = "Maneuver")
Behavior = gsub(pattern = ".*Maneuver.*", replacement = "Maneuver", x = Behavior),
# re-code all transit as "Transit" (e.g., "TransitA" = "Transit")
# important that this happens AFTER the Maneuver line above so that "TransitAManeuver" doesn't get re-coded
Behavior = gsub(pattern = ".*Transit.*", replacement = "Transit", x = Behavior),
Behavior = gsub(pattern = "CPAManeuver", replacement = "Maneuver", x = Behavior),
Behavior = gsub(pattern = "CPA", replacement = "Transit", x = Behavior),
Behavior = gsub(pattern = " ", replacement = "", x = Behavior),
Behavior = na_if(Behavior, ""),
Behavior = replace_na(Behavior, "Not_Assigned"))
# Count instances of each behavior per date-hour
hr_tally <- all_selns_hr |>
mutate(Behavior = as.factor(Behavior)) |>
group_by(Behavior, Begin_Date, Begin_Hour) |>
count() |>
# pivot wider to get behavs as columns and fill missing values with 0
pivot_wider(names_from = Behavior,
values_from = n,
values_fill = 0)
# create a new df with all hours for the whole deployment
date_range_dep <- seq.Date(from = start_dep_date, to = end_dep_date, by = "day") |>
crossing(seq(0,23,1))
# rename columns
names(date_range_dep) <- c("Begin_Date","Begin_Hour")
# join 2 data frames together to add behavior tally
hourly_pres <- date_range_dep |>
left_join(hr_tally, by = c("Begin_Date","Begin_Hour")) |>
replace_na(list(Transit = 0, Maneuver = 0))
# bring in Notes from all_selns_hr
seln_notes <- aggregate(Notes ~ Begin_Date + Begin_Hour, data = all_selns_hr, paste0, collapse = "; ") |>
# get rid of blank entries for notes
filter(Notes != "" & Notes != "; ")
hourly_pres_notes <- hourly_pres |>
left_join(seln_notes, by = c("Begin_Date","Begin_Hour")) |>
mutate(SiteID = site_id)
write.csv(hourly_pres_notes,
paste0("data_outputs/",site_id,"_",dep_id,"_Vessel_Hourly_Presence.csv"))
start_dep_date <- as_date(dlg_input(message = "Start date: YYYY-MM-DD")$res)
end_dep_date <- as_date(dlg_input(message = "End date: YYYY-MM-DD")$res)
start_dep_date <- as_date(dlg_input(message = "Start date: YYYY-MM-DD")$res)
end_dep_date <- as_date(dlg_input(message = "End date: YYYY-MM-DD")$res)
all_selns_hr <- all_selns |>
mutate(Begin_Clock = as_datetime(Begin_Clock, format = "%H:%M:%OS"),
End_Clock = as_datetime(End_Clock, format = "%H:%M:%OS"),
Begin_Date = as_datetime(Begin_Date, format = "%Y/%m/%d"),
Begin_Hour = hour(Begin_Clock),
End_Hour = hour(End_Clock),
# re-code anything with a maneuver as "Maneuver" (e.g., "Maneuver+CPA" = "Maneuver")
Behavior = gsub(pattern = ".*Maneuver.*", replacement = "Maneuver", x = Behavior),
# re-code all transit as "Transit" (e.g., "TransitA" = "Transit")
# important that this happens AFTER the Maneuver line above so that "TransitAManeuver" doesn't get re-coded
Behavior = gsub(pattern = ".*Transit.*", replacement = "Transit", x = Behavior),
Behavior = gsub(pattern = "CPAManeuver", replacement = "Maneuver", x = Behavior),
Behavior = gsub(pattern = "CPA", replacement = "Transit", x = Behavior),
Behavior = gsub(pattern = " ", replacement = "", x = Behavior),
Behavior = na_if(Behavior, ""),
Behavior = replace_na(Behavior, "Not_Assigned"))
# Count instances of each behavior per date-hour
hr_tally <- all_selns_hr |>
mutate(Behavior = as.factor(Behavior)) |>
group_by(Behavior, Begin_Date, Begin_Hour) |>
count() |>
# pivot wider to get behavs as columns and fill missing values with 0
pivot_wider(names_from = Behavior,
values_from = n,
values_fill = 0)
# create a new df with all hours for the whole deployment
date_range_dep <- seq.Date(from = start_dep_date, to = end_dep_date, by = "day") |>
crossing(seq(0,23,1))
# rename columns
names(date_range_dep) <- c("Begin_Date","Begin_Hour")
# join 2 data frames together to add behavior tally
hourly_pres <- date_range_dep |>
left_join(hr_tally, by = c("Begin_Date","Begin_Hour")) |>
replace_na(list(Transit = 0, Maneuver = 0))
# bring in Notes from all_selns_hr
seln_notes <- aggregate(Notes ~ Begin_Date + Begin_Hour, data = all_selns_hr, paste0, collapse = "; ") |>
# get rid of blank entries for notes
filter(Notes != "" & Notes != "; ")
hourly_pres_notes <- hourly_pres |>
left_join(seln_notes, by = c("Begin_Date","Begin_Hour")) |>
mutate(SiteID = site_id)
write.csv(hourly_pres_notes,
paste0("data_outputs/",site_id,"_",dep_id,"_Vessel_Hourly_Presence.csv"))
# Load data ---------------------------------------------------------------
# For each deployment in the dep_info list, load in hourly presence table & compiled selection table
hp_og <- dep_info |>
map(~read_csv(choose.files(caption = paste0({.}$site_id, {.}$dep_id, " Hourly Presence sheet .csv"))))|>
# use imap() to get info based on index of each iteration
# in this case, we want the name of the list element, designated as ".y"
imap(~mutate(., Dep_ID = .y))
# For each deployment in the dep_info list, load in compiled selection table
selns_og <- dep_info |>
map(~read_delim(choose.files(caption = paste0({.}$site_id, {.}$dep_id, " Complied seln table .txt"))))|>
# use imap() to get info based on index of each iteration
# in this case, we want the name of the list element, designated as ".y"
imap(~mutate(., Dep_ID = .y))
# For each deployment in the dep_info list, load in I-O excel files
ins_out_og <- dep_info |>
map(~read_xlsx(choose.files(caption = paste0({.}$site_id, {.}$dep_id, " I-O table .xlsx"))))|>
# use imap() to get info based on index of each iteration
# in this case, we want the name of the list element, designated as ".y"
imap(~mutate(., Dep_ID = .y))
# For each deployment in the dep_info list, load in compiled selection table
selns_og <- dep_info |>
map(~read_delim(choose.files(caption = paste0({.}$site_id, {.}$dep_id, " Complied seln table .txt"))))|>
# use imap() to get info based on index of each iteration
# in this case, we want the name of the list element, designated as ".y"
imap(~mutate(., Dep_ID = .y))
# For each deployment in the dep_info list, load in I-O excel files
ins_out_og <- dep_info |>
map(~read_xlsx(choose.files(caption = paste0({.}$site_id, {.}$dep_id, " I-O table .xlsx"))))|>
# use imap() to get info based on index of each iteration
# in this case, we want the name of the list element, designated as ".y"
imap(~mutate(., Dep_ID = .y))
#### Add some columns, update time zone ####
# making this to be able to add column names
new_cols <- c("Maneuver" = 0,"Transit" = 0, "Not_Assigned" = 0)
hp_allcols <- hp_og |>
# add columns for Transit and Maneuver if they don't exist
map(~add_column(., !!!new_cols[!names(new_cols) %in% names(.)])
)
# Hourly presence
hp_data <- hp_allcols |>
map(~rename(.,
any_of(c("TR" = "Transit",
"M" = "Maneuver",
"Dep" = "Dep_ID")))) |>
map(~relocate(.,
TR, .after = last_col())) |>
map(~relocate(.,
Not_Assigned, .after = last_col())) |>
map(~relocate(.,
M, .after = last_col())) |>
map2(.y = dep_info,
~mutate(.x,
Site_ID = {.y}$site_id,
Dep_ID = {.y}$dep_id,
Total_Vessels = rowSums(across(c(TR, M))),
# create y/n column for vessel presence
ves_yn = ifelse(Total_Vessels == 0, "N", "Y"),
# pull hour as time object along with date
Hr_time = paste(Begin_Date, Begin_Hour, ":00"),
# get components of date-time object and assign time zone
Hr_time = parse_date_time(Hr_time, "ymd H:M", tz = {.y}$tz_files),
# change to local time zone
Hr_local = with_tz(Hr_time, tzone = {.y}$tz_local),
# pull out new hour and date in local time
Begin_Hour_loc = as.numeric(hour(Hr_local)),
Begin_Date_loc = date(Hr_local),
# add weekday column
Weekday = weekdays(Begin_Date_loc))) |>
bind_rows()
# Create CSV to make data input easier. Maybe eventually add some logic in script to bypass generating this?
write_csv(hp_data, "data_outputs/total_ves_hp_by_site.csv")
# Selection tables --------------------------------------------------------
# reshape selection tables to plot duration
selns_data <- selns_og |>
map(~rename(., "Dep" = "Dep_ID")) |>
map2(.y = dep_info,
~mutate(.x,
Begin_Date = ymd(Begin_Date),
Begin_file_date = ymd(Begin_file_date),
Site_ID = {.y}$site_id,
# Dep = {.y}$dep_id,
# re-code anything with a maneuver as "Maneuver" (e.g., "Maneuver+CPA" = "Maneuver")
Behavior = gsub(pattern = ".*Maneuver.*", replacement = "Maneuver", x = Behavior),
# re-code all transit as "Transit" (e.g., "TransitA" = "Transit")
# important that this happens AFTER the Maneuver line above so that "TransitAManeuver" doesn't get re-coded
Behavior = gsub(pattern = ".*Transit.*", replacement = "Transit", x = Behavior),
Behavior = gsub(pattern = "CPAManeuver", replacement = "Maneuver", x = Behavior),
Behavior = gsub(pattern = "CPA", replacement = "Transit", x = Behavior),
Behavior = gsub(pattern = " ", replacement = "", x = Behavior),
DeltaHours = Delta_Time_s/3600,
# Total_Vessels = rowSums(across(c(TR,M))),
# pull hour as time object along with date
Hr_time = paste(Begin_Date, Begin_Clock),
# get components of date-time object and assign time zone
Hr_time = parse_date_time(Hr_time, "y/m/d H:M:S", tz = {.y}$tz_files),
# change to local time zone
Hr_local = with_tz(Hr_time, tzone = {.y}$tz_local),
# pull out new hour and date in local time
Begin_Hour_loc = as.numeric(hour(Hr_local)),
Begin_Date_loc = date(Hr_local),
# add weekday column
Weekday = weekdays(Begin_Date_loc))) |>
bind_rows()
# write csv for easier input later
write.csv(selns_data, "data_outputs/total_ves_selns_data_by_site.csv")
# Bind rows to get df for inside-outside tables
# don't need to do other adjustments for time zone etc bc will join with selns_data which has
# Begin_hour_loc and Begin_date_loc fields
ins_out_data <- ins_out_og |>
map(~select(., Filename, Date, Selection, used, pins_sm, pins_med, pins_lg, pins_ovrll, Dep_ID)) |>
map(~mutate(., Date = as.numeric(Date),
Date = as.character(Date))) |>
bind_rows()
# write csv for easier input later
write.csv(ins_out_data, "data_outputs/total_ves_ins_out_by_site.csv")
ins_vessels <- ins_out_data |>
filter(used == 1) |>
filter(pins_sm >= 0.75) |>
mutate(begin_file_date = ymd(str_sub(Date, 1,6)),
seln_num = as.numeric(gsub(pattern = "S", replacement = "", x = Selection)))|>
left_join(selns_data,
by = c("Dep_ID" = "Dep",
"seln_num" = "Selection",
"begin_file_date" = "Begin_file_date"))
#### Ins Park tables -- reshape into hp ####
# get counts per site per date per hour for inside vessels
ins_hp <- inside_tables_to_hp(ins_table = ins_vessels)
# join inside vessels to total vessels
total_ins_hp <- hp_data |>
left_join(ins_hp,
by = c("Dep" = "Dep_ID",
"Begin_Date_loc" = "Begin_Date_loc",
"Begin_Hour_loc" = "Begin_Hour_loc"))
#
# #### bring all HP data together ####
# all_sites_hp <- as.data.frame(rbind(hp_cgmp_local, hp_simp_local,
#                      hp_dne_local, hp_mur_local, hp_ngn_local,
#                      hp_trw_local, hp_sws_local, hp_geo_local, hp_jur_local))
write.csv(total_ins_hp, "data_outputs/hourly_pres_allsites_local.csv")
View(total_ins_hp)
#' ---------------------------------------------------------
#'
#'
#' Summarize vessel activity across 9 marine parks
#'
#' Updated Dec 2024
#' ---------------------------------------------------------
#### Load libraries ####
# NOAA-approved tidyverse
tidyverse_short<-c("broom","cli","crayon","dbplyr","dplyr","dtplyr","forcats","ggplot2","googledrive","googlesheets4","hms","httr","jsonlite","lubridate","magrittr","modelr","pillar","purrr","readr","readxl","reprex","rlang","rstudioapi","rvest","stringr","tibble","tidyr","xml2")
lapply(tidyverse_short, require, character.only = TRUE)
# source helper file
source("scripts/AMP_summary_ves_funs.R")
#### Load in data ####
# Assign user-defined inputs ----------------------------------------------
# Since server folders are in a standard structure, use parent folder to get list of all deployments
dep_names <- list.dirs(tk_choose.dir(caption = "Select parent dir for all deployment folders"), recursive = FALSE, full.names = FALSE)
# select the deployment(s) to be plotted
dep_list <- dlg_list(title = "Select deployments to plot", choices = dep_names, multiple = TRUE)$res |>
str_sub(start = 16)
# apply getDeploymentInfo() from AMP_pkgs_funs.R to each deployment
#   prompts user for site name, start/end date, and time zones
dep_info <- dep_list |>
map(~getDeploymentInfo(.)) |>
set_names(dep_list)
